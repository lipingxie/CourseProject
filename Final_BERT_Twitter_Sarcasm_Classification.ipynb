{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final BERT Twitter Sarcasm Classification V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e3b3cb74f0b452897e2a3ae4bd4f87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1b9b822437cb4632b2810a5f2d383fa6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e0b7ad42160342979d39b5f56b97ac0f",
              "IPY_MODEL_6a23ed07887545be9767d172521a1a50"
            ]
          }
        },
        "1b9b822437cb4632b2810a5f2d383fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0b7ad42160342979d39b5f56b97ac0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8186c4aba9fc43148ea1ff046ed45da7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 565,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 565,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f619f3e38284090a1267d692703d17f"
          }
        },
        "6a23ed07887545be9767d172521a1a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d7074104bc84714b1d748f0f4e08ab7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 565/565 [00:00&lt;00:00, 6.05kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ac5f706804041358305a2aca811a392"
          }
        },
        "8186c4aba9fc43148ea1ff046ed45da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f619f3e38284090a1267d692703d17f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d7074104bc84714b1d748f0f4e08ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ac5f706804041358305a2aca811a392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0dedd8fc8c64cafb7a92b1297336f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b7371f09eb864f8491e2777253756bb4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cce52f0b144649efaa8ff842beda4ef3",
              "IPY_MODEL_78e5e06765ae4717a89e154c74d657bb"
            ]
          }
        },
        "b7371f09eb864f8491e2777253756bb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cce52f0b144649efaa8ff842beda4ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e67adc161dd549c893ecb909bea0a24e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dab598ad0e8940278a33bff0db92801d"
          }
        },
        "78e5e06765ae4717a89e154c74d657bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28bff1bb5ab941e98d97fb7a320bfa89",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 3.30MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d49e7df408a49089b5d58914b2d6215"
          }
        },
        "e67adc161dd549c893ecb909bea0a24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dab598ad0e8940278a33bff0db92801d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28bff1bb5ab941e98d97fb7a320bfa89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d49e7df408a49089b5d58914b2d6215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84f994ff5957403696de8162f241508b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_962703cd49464f62acd4936e93862a76",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_451f8fa0306b41cc8d091dfdbd826f15",
              "IPY_MODEL_b06d0bfff8124f2ea9474019ad5183af"
            ]
          }
        },
        "962703cd49464f62acd4936e93862a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "451f8fa0306b41cc8d091dfdbd826f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_758c56a6b3774a4daef30e590ccae4d6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de93b0b0f1514cf5810f7c0395229279"
          }
        },
        "b06d0bfff8124f2ea9474019ad5183af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_384e2ad0c9794ea9ae93c8f24bfe9d26",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 2.82MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fee1cfa22db3498aa0eaa661ae76d0a1"
          }
        },
        "758c56a6b3774a4daef30e590ccae4d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de93b0b0f1514cf5810f7c0395229279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "384e2ad0c9794ea9ae93c8f24bfe9d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fee1cfa22db3498aa0eaa661ae76d0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8af386c1a61f4678b283e73fb62e09ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd02ca6a5f9946a7ab0e3105ab37f2b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee2b30e5403247f797c46fd91f7be3e0",
              "IPY_MODEL_1b67ae3476254e6a9d89dc1d93918f45"
            ]
          }
        },
        "bd02ca6a5f9946a7ab0e3105ab37f2b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee2b30e5403247f797c46fd91f7be3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d0f239c166841a0af887020cbd4ed47",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501204462,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501204462,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b5289bc561147f9ad50ce8ef04f3715"
          }
        },
        "1b67ae3476254e6a9d89dc1d93918f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_905ad01535004908a82fc3a3ff36064d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:07&lt;00:00, 65.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6db1d88f0db44130ae486999d6061712"
          }
        },
        "0d0f239c166841a0af887020cbd4ed47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b5289bc561147f9ad50ce8ef04f3715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "905ad01535004908a82fc3a3ff36064d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6db1d88f0db44130ae486999d6061712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrZ1VB23qHXe"
      },
      "source": [
        "## **CS410 Project:**\r\n",
        "## **Text Classification Competition: Twitter Sarcasm Detection**\r\n",
        "\r\n",
        "**Team Name:** \r\n",
        "*   Team Commonwealth\r\n",
        "\r\n",
        "**Team Members:**\r\n",
        "*   Zuliang Weng / zwe\r\n",
        "*   Zijing Chen / zijingc3\r\n",
        "*   Liping Xie / lipingx2 (captain)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "## 1.1. Using Colab GPU for Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0iOY8zvZzL"
      },
      "source": [
        "Make sure GPU is assigned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437f9eee-c5a4-4c4e-aee5-aa0fc38cc4c8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "## 1.2. Install the Hugging Face Library\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7f937a-d219-460b-ecc9-0210352131b0"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 28.4MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 31.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 33.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 33.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 28.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 27.7MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 22.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 21.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 22.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 22.9MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 22.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 22.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 22.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 22.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 22.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 22.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 22.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 22.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 962kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 22.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 22.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 56.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=1e768ea5aa08993bd52a22102520f725eb27252b4fcbdfbe02bc2e34bf14c168\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "# 2. Prepare train data and test data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn"
      },
      "source": [
        "## 2.1. Upload files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZNVW6xd0T0X"
      },
      "source": [
        "upload train.jsonl and test.jsonl files here to this instance's file system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "0df1dfb7-25b7-439c-89c3-b701b9c3b046"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e847ecb4-a739-4db4-87ca-70bfc5952220\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e847ecb4-a739-4db4-87ca-70bfc5952220\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.jsonl to test.jsonl\n",
            "Saving train.jsonl to train.jsonl\n",
            "User uploaded file \"test.jsonl\" with length 1308642 bytes\n",
            "User uploaded file \"train.jsonl\" with length 3876480 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "## 2.2. Parse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeyVCXT31EZQ"
      },
      "source": [
        "Since train data and test data are in jsonl format, we will need to manually convert them list and then pass into pandas to create a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "LIBhcrjv02ut",
        "outputId": "ebf61e0b-b68b-4118-f055-8977f528e919"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def load_jsonl(input_path) -> list:\n",
        "    data = []\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line.rstrip('\\n|\\r').replace('@USER', '')))\n",
        "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
        "    return data\n",
        "\n",
        "train_data = load_jsonl('train.jsonl')\n",
        "db_data = []\n",
        "db_cols = ['label', 'response']\n",
        "for d in train_data:\n",
        "    db_data.append([])\n",
        "    for col in db_cols:\n",
        "        db_data[-1].append(d.get(col, float('nan')))\n",
        "        \n",
        "df = pd.DataFrame(db_data, columns=db_cols)\n",
        "\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "df.loc[df.label == \"SARCASM\"].sample(5)[['response', 'label']]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 5000 records from train.jsonl\n",
            "Number of training sentences: 5,000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2215</th>\n",
              "      <td>I guess I should have put at the end of my ...</td>\n",
              "      <td>SARCASM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>so BASICALLY the same way we felt for the l...</td>\n",
              "      <td>SARCASM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1944</th>\n",
              "      <td>Yep and you've demonstrated your ignorance by...</td>\n",
              "      <td>SARCASM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1962</th>\n",
              "      <td>terrible practice . How dare you let your kid...</td>\n",
              "      <td>SARCASM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2071</th>\n",
              "      <td>me neither ! But , i did kinda need a table ....</td>\n",
              "      <td>SARCASM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               response    label\n",
              "2215     I guess I should have put at the end of my ...  SARCASM\n",
              "2022     so BASICALLY the same way we felt for the l...  SARCASM\n",
              "1944   Yep and you've demonstrated your ignorance by...  SARCASM\n",
              "1962   terrible practice . How dare you let your kid...  SARCASM\n",
              "2071   me neither ! But , i did kinda need a table ....  SARCASM"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Change labels to numeric values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f8363b-cd8d-4397-9dec-14782e810cfd"
      },
      "source": [
        "sentences = df.response.values\n",
        "labels = df.label.apply(lambda x: 1 if x == \"SARCASM\" else 0).values\n",
        "labels"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmIICea8dyeN"
      },
      "source": [
        "# 3. Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5"
      },
      "source": [
        "## 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "There are many different pre-trained BERT models available. Each model comes with its own tokenizer. We need to make sure we used the correct tokenizer as we experient with different models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198,
          "referenced_widgets": [
            "2e3b3cb74f0b452897e2a3ae4bd4f87b",
            "1b9b822437cb4632b2810a5f2d383fa6",
            "e0b7ad42160342979d39b5f56b97ac0f",
            "6a23ed07887545be9767d172521a1a50",
            "8186c4aba9fc43148ea1ff046ed45da7",
            "2f619f3e38284090a1267d692703d17f",
            "6d7074104bc84714b1d748f0f4e08ab7",
            "8ac5f706804041358305a2aca811a392",
            "e0dedd8fc8c64cafb7a92b1297336f03",
            "b7371f09eb864f8491e2777253756bb4",
            "cce52f0b144649efaa8ff842beda4ef3",
            "78e5e06765ae4717a89e154c74d657bb",
            "e67adc161dd549c893ecb909bea0a24e",
            "dab598ad0e8940278a33bff0db92801d",
            "28bff1bb5ab941e98d97fb7a320bfa89",
            "4d49e7df408a49089b5d58914b2d6215",
            "84f994ff5957403696de8162f241508b",
            "962703cd49464f62acd4936e93862a76",
            "451f8fa0306b41cc8d091dfdbd826f15",
            "b06d0bfff8124f2ea9474019ad5183af",
            "758c56a6b3774a4daef30e590ccae4d6",
            "de93b0b0f1514cf5810f7c0395229279",
            "384e2ad0c9794ea9ae93c8f24bfe9d26",
            "fee1cfa22db3498aa0eaa661ae76d0a1"
          ]
        },
        "outputId": "0c6a0b86-9006-4fb3-be4c-0f6028c6bc55"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from transformers import pipeline,AutoTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "# test 1\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
        "# ...\n",
        "\n",
        "# test 2\n",
        "# task='irony'\n",
        "# MODEL = \"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "# print(MODEL)\n",
        "\n",
        "# test 3\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "print(MODEL)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e3b3cb74f0b452897e2a3ae4bd4f87b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=565.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0dedd8fc8c64cafb7a92b1297336f03",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84f994ff5957403696de8162f241508b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "cardiffnlp/twitter-roberta-base\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aop80_K4ebmB"
      },
      "source": [
        "Examine the tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c972868d-4f06-49ae-fe6e-b87d11de598a"
      },
      "source": [
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:     I don't get this .. obviously you do care or you would've moved right along .. instead you decided to care and troll her ..\n",
            "Tokenized:  ['Ġ', 'Ġ', 'ĠI', 'Ġdon', \"'t\", 'Ġget', 'Ġthis', 'Ġ..', 'Ġobviously', 'Ġyou', 'Ġdo', 'Ġcare', 'Ġor', 'Ġyou', 'Ġwould', \"'ve\", 'Ġmoved', 'Ġright', 'Ġalong', 'Ġ..', 'Ġinstead', 'Ġyou', 'Ġdecided', 'Ġto', 'Ġcare', 'Ġand', 'Ġtroll', 'Ġher', 'Ġ..']\n",
            "Token IDs:  [1437, 1437, 38, 218, 75, 120, 42, 29942, 3334, 47, 109, 575, 50, 47, 74, 348, 1410, 235, 552, 29942, 1386, 47, 1276, 7, 575, 8, 29989, 69, 29942]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viKGCCh8izww"
      },
      "source": [
        "## 3.2. Required Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDcqNlvVhL5W"
      },
      "source": [
        "BERT requires tokens to fit certain format:\n",
        "1. Add special tokens to the start and end of each sentence.\n",
        "2. Pad & truncate all sentences to a single constant length.\n",
        "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
        "\n",
        "BERT has two constraints:\n",
        "\n",
        "1. All sentences must be padded or truncated to a single, fixed length.\n",
        "2. The maximum sentence length is 512 tokens.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ"
      },
      "source": [
        "## 3.3. Tokenize Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U28qy4P-NwQ9"
      },
      "source": [
        "First, let's find out the max_len in all the sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83b0dc0-0203-47b6-884c-79bb6620baec"
      },
      "source": [
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RNi-F1Wfgld"
      },
      "source": [
        "\r\n",
        "Tokenize all of the sentences and map the tokens to thier word IDs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f456c28d-3323-4303-8703-84c23941377c"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sentence in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens = True,             \n",
        "        max_length = max_len,\n",
        "        pad_to_max_length = True,\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt')\n",
        "       \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:     I don't get this .. obviously you do care or you would've moved right along .. instead you decided to care and troll her ..\n",
            "Token IDs: tensor([    0,  1437,  1437,    38,   218,    75,   120,    42, 29942,  3334,\n",
            "           47,   109,   575,    50,    47,    74,   348,  1410,   235,   552,\n",
            "        29942,  1386,    47,  1276,     7,   575,     8, 29989,    69, 29942,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "## 3.4. Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06"
      },
      "source": [
        "split our training data into training set and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06a2759-2422-4f2d-fd61-f97429084d95"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "#train_ratio = 0.8\n",
        "# train_ratio = 0.9\n",
        "train_ratio = 0.9\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4,500 training samples\n",
            "  500 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN"
      },
      "source": [
        "using a DataLoader will help us save memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf1b5bf-2a0a-4ad6-da20-05e27299cbd6"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    batch_size = batch_size)\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    sampler = SequentialSampler(val_dataset),\n",
        "    batch_size = batch_size)\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "# 4. Fine-tune BERT Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewi7ujP5tXnA"
      },
      "source": [
        "* First we modify the pre-trained BERT model to give outputs for classification.\r\n",
        "* Then we continue training the model on our dataset until to improve precision and recall. \r\n",
        "\r\n",
        "Here is the a list that we have experimented\r\n",
        "* BertModel\r\n",
        "* twitter-roberta-base (chosen model)\r\n",
        "* twitter-roberta-base-irony"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## 4.1. Download twitter-roberta-base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8af386c1a61f4678b283e73fb62e09ec",
            "bd02ca6a5f9946a7ab0e3105ab37f2b3",
            "ee2b30e5403247f797c46fd91f7be3e0",
            "1b67ae3476254e6a9d89dc1d93918f45",
            "0d0f239c166841a0af887020cbd4ed47",
            "8b5289bc561147f9ad50ce8ef04f3715",
            "905ad01535004908a82fc3a3ff36064d",
            "6db1d88f0db44130ae486999d6061712"
          ]
        },
        "outputId": "daa3125e-fa8c-4fcc-89f2-0f975bfd2c9c"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "# Test 1\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "# model = BertForSequenceClassification.from_pretrained(\n",
        "#     \"bert-large-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "#     num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "#                     # You can increase this for multi-class tasks.   \n",
        "#     output_attentions = False, # Whether the model returns attentions weights.\n",
        "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "# )\n",
        "# ...\n",
        "# Test 3\n",
        "# Note that MODEL was defined earlier when we choose the tokenizer\n",
        "\n",
        "print(\"Using model: \" + MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model.save_pretrained(MODEL)\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using model: cardiffnlp/twitter-roberta-base\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8af386c1a61f4678b283e73fb62e09ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501204462.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a252fd3f-f044-4a8c-f810-c7568a03d65e"
      },
      "source": [
        "# Examine the model\n",
        "\n",
        "params = list(model.named_parameters())\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "roberta.embeddings.word_embeddings.weight               (50265, 768)\n",
            "roberta.embeddings.position_embeddings.weight             (514, 768)\n",
            "roberta.embeddings.token_type_embeddings.weight             (1, 768)\n",
            "roberta.embeddings.LayerNorm.weight                           (768,)\n",
            "roberta.embeddings.LayerNorm.bias                             (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.query.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.key.bias               (768,)\n",
            "roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.value.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
            "roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
            "roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
            "roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
            "roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n",
            "roberta.encoder.layer.0.output.dense.bias                     (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "classifier.dense.weight                                   (768, 768)\n",
            "classifier.dense.bias                                         (768,)\n",
            "classifier.out_proj.weight                                  (2, 768)\n",
            "classifier.out_proj.bias                                        (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "For training,\n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6677d107-3e71-4dc0-92ae-1cc05f3ec162"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Use AdamW optimizer\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 2e-5,\n",
        "    eps = 1e-8)\n",
        "\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = total_steps)\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5"
      },
      "source": [
        "The following training loop is largely based on the contribution of Stas Bekman.\n",
        "\n",
        "Essentially which loop has a training phase and a validation phase. It also detects over-fitting by using validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W"
      },
      "source": [
        "Define some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d714a6d8-b1ab-4723-ae6e-99b7ef119b11"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# Takes a time in seconds and returns a string hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N"
      },
      "source": [
        "Finally we are ready to start to fine-tune to model\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649b5b4d-2a2c-402e-9849-f1d1d9976734"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        results = model(\n",
        "            b_input_ids,\n",
        "            token_type_ids=None,\n",
        "            attention_mask=b_input_mask,\n",
        "            labels=b_labels)\n",
        "        loss = results[0]\n",
        "        logits = results[1]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            results = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask,\n",
        "                labels=b_labels)\n",
        "            loss = results[0]\n",
        "            logits = results[1]\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    141.    Elapsed: 0:00:22.\n",
            "  Batch    80  of    141.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    141.    Elapsed: 0:01:08.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.40\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    141.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    141.    Elapsed: 0:00:48.\n",
            "  Batch   120  of    141.    Elapsed: 0:01:12.\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epcoh took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.45\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    141.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    141.    Elapsed: 0:00:48.\n",
            "  Batch   120  of    141.    Elapsed: 0:01:13.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.41\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    141.    Elapsed: 0:00:24.\n",
            "  Batch    80  of    141.    Elapsed: 0:00:48.\n",
            "  Batch   120  of    141.    Elapsed: 0:01:13.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.46\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:05:48 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Review the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1bfc794d-69aa-42cc-d4cc-929051b8da35"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.24</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.51         0.40           0.80       0:01:20         0:00:03\n",
              "2               0.35         0.45           0.81       0:01:25         0:00:03\n",
              "3               0.24         0.41           0.83       0:01:25         0:00:03\n",
              "4               0.15         0.46           0.83       0:01:25         0:00:03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Pay special attention to the validation loss. If it starts go increase, we have a over-fitting problem. \n",
        "That suggests we should limit the number of epoch.\n",
        "\n",
        "We can plot a chart to show the trend of training loss and validation loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "63c4adbc-9f05-460d-e32b-23d6026e9202"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# 5. Predict on the test data\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### 5.1. Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "Prepare the test data just as how we prepare the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ceb016-1a41-40d6-d471-c0d14c10aeab"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_data = load_jsonl('test.jsonl')\n",
        "db_data = []\n",
        "db_cols = ['id', 'response']\n",
        "for d in test_data:\n",
        "    db_data.append([])\n",
        "    for col in db_cols:\n",
        "        db_data[-1].append(d.get(col, float('nan')))\n",
        "        \n",
        "df2 = pd.DataFrame(db_data, columns=db_cols)\n",
        "df2['label'] = 1\n",
        "print('Number of test sentences: {:,}\\n'.format(df2.shape[0]))\n",
        "\n",
        "df2.sample(5)\n",
        "\n",
        "sentences = df2.response.values\n",
        "labels = df2.label.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sentence in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens = True,\n",
        "        max_length = max_len,\n",
        "        pad_to_max_length = True,\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt')\n",
        "      \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data) # note that we use sequential sampler because we are not splitting the data set.\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 1800 records from test.jsonl\n",
            "Number of test sentences: 1,800\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "## 5.2. Predict on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46048e5a-b79e-45ec-cd0a-5eb4ec7393d5"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      outputs = model(\n",
        "          b_input_ids, \n",
        "          token_type_ids=None, \n",
        "          attention_mask=b_input_mask)\n",
        "  # note that outputs won't have loss in evaluation mode\n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  predictions.append(logits)\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,800 test sentences...\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrjAPX2V-l4"
      },
      "source": [
        "Generate the final prediction based on the score, and download the result as answer.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a12c4d31-5f9c-4f35-9b8f-58e8c256177f"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "df2['pred'] = flat_predictions\n",
        "df2['result'] = df2.pred.apply(lambda x: \"SARCASM\" if x == 1 else \"NOT_SARCASM\")\n",
        "df2[['id', 'result']].to_csv(\"answer.txt\", header=False, index=False)\n",
        "\n",
        "\n",
        "files.download('answer.txt')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_787b5e9d-cf52-4926-962d-d63096588f09\", \"answer.txt\", 40025)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHeGO-G1N6vL"
      },
      "source": [
        "All the testing results are detailed in the Project Details document.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlQG7qgkmf4n"
      },
      "source": [
        "BERT is a powerful tool when it comes to classification problem. We are able to create a reasonaly useful model to detect sarcasm in tweets without using a lot of resource for training the models from scratch. \r\n",
        "\r\n",
        "**References**\r\n",
        "* https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109\r\n",
        "* https://mccormickml.com/\r\n",
        "* https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\r\n",
        "* https://github.com/stas00?tab=repositories"
      ]
    }
  ]
}